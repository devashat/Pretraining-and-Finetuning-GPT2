{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6560,
     "status": "ok",
     "timestamp": 1707955381654,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "pWtlJci5FeU5"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707955381654,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "HreSZcU-ZUHX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, GPT2Config, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5020,
     "status": "ok",
     "timestamp": 1707955386669,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "vcacA0TscEev",
    "outputId": "b2dabc6c-55f6-4d00-c201-05e092ce009f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (0.27.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from accelerate) (2.2.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: requests in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2472,
     "status": "ok",
     "timestamp": 1707955390527,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "RgwO05blckix",
    "outputId": "64405568-55ca-4640-9d68-dacc259ce66c"
   },
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1707955391904,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "ax4pzl5FclJW",
    "outputId": "f9861ad0-fee3-4dd5-d47c-96f309472577"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at devashat/244-final and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = GPT2Config.from_pretrained('devashat/244-final', num_labels=18)\n",
    "model = GPT2ForSequenceClassification.from_pretrained('devashat/244-final', config=config)\n",
    "model.config.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1707955391904,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "yqTVO9-jeucU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data_path = 'train.csv'\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "\n",
    "test_data_path = 'test.csv'\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1707955391904,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "O-J-bavyfWkL",
    "outputId": "4df848f8-379b-4d54-a351-8110d7494ed5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterances</th>\n",
       "      <th>Core Relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who plays luke on star wars new hope</td>\n",
       "      <td>movie.starring.actor movie.starring.character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>show credits for the godfather</td>\n",
       "      <td>movie.starring.actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who was the main actor in the exorcist</td>\n",
       "      <td>movie.starring.actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who played dory on finding nemo</td>\n",
       "      <td>movie.starring.actor movie.starring.character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who was the female lead in resident evil</td>\n",
       "      <td>movie.starring.actor actor.gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>revenue for titanic</td>\n",
       "      <td>movie.gross_revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>total titanic revenues</td>\n",
       "      <td>movie.gross_revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>what was the revenue for toy story 3</td>\n",
       "      <td>movie.gross_revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>dark knight revenue</td>\n",
       "      <td>movie.gross_revenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>how much did the dark night generate</td>\n",
       "      <td>movie.gross_revenue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2253 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    utterances  \\\n",
       "0         who plays luke on star wars new hope   \n",
       "1               show credits for the godfather   \n",
       "2       who was the main actor in the exorcist   \n",
       "3              who played dory on finding nemo   \n",
       "4     who was the female lead in resident evil   \n",
       "...                                        ...   \n",
       "2248                       revenue for titanic   \n",
       "2249                    total titanic revenues   \n",
       "2250      what was the revenue for toy story 3   \n",
       "2251                       dark knight revenue   \n",
       "2252      how much did the dark night generate   \n",
       "\n",
       "                                     Core Relations  \n",
       "0     movie.starring.actor movie.starring.character  \n",
       "1                              movie.starring.actor  \n",
       "2                              movie.starring.actor  \n",
       "3     movie.starring.actor movie.starring.character  \n",
       "4                 movie.starring.actor actor.gender  \n",
       "...                                             ...  \n",
       "2248                            movie.gross_revenue  \n",
       "2249                            movie.gross_revenue  \n",
       "2250                            movie.gross_revenue  \n",
       "2251                            movie.gross_revenue  \n",
       "2252                            movie.gross_revenue  \n",
       "\n",
       "[2253 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.drop('IOB Slot tags', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1707955391905,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "ZrIcaDW-f8WL",
    "outputId": "8ef967c1-f7cd-4e7d-dbf7-4990de6654c4"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.dropna(subset=['Core Relations'])\n",
    "train_data['Core Relations'].fillna('none', inplace=True)\n",
    "train_data['Core Relations'] = train_data['Core Relations'].astype(str)\n",
    "train_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1707955391905,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "oT2onQ0IDuzn",
    "outputId": "c79fe199-6f69-4c43-9058-67e268721eaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actor.gender',\n",
       " 'gr.amount',\n",
       " 'movie.country',\n",
       " 'movie.directed_by',\n",
       " 'movie.estimated_budget',\n",
       " 'movie.genre',\n",
       " 'movie.gross_revenue',\n",
       " 'movie.initial_release_date',\n",
       " 'movie.language',\n",
       " 'movie.locations',\n",
       " 'movie.music',\n",
       " 'movie.produced_by',\n",
       " 'movie.production_companies',\n",
       " 'movie.rating',\n",
       " 'movie.starring.actor',\n",
       " 'movie.starring.character',\n",
       " 'movie.subjects',\n",
       " 'person.date_of_birth']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_core_relations = set()\n",
    "for relations in train_data['Core Relations']:\n",
    "    unique_core_relations.update(relations.split())\n",
    "\n",
    "unique_core_relations = sorted(list(unique_core_relations))\n",
    "\n",
    "unique_core_relations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707955391905,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "7YuoWKTtfEIQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_split, validation_split = train_test_split(train_data, test_size=0.1, train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707955391905,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "8y4iOm36fQIf"
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(data):\n",
    "\n",
    "    one_hot_vectors = []\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        one_hot_vector = dict.fromkeys(unique_core_relations, 0)\n",
    "        for relation in row['Core Relations'].split():\n",
    "            if relation in one_hot_vector:\n",
    "                one_hot_vector[relation] = 1\n",
    "        one_hot_vectors.append(one_hot_vector)\n",
    "\n",
    "    return one_hot_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707955391905,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "lPSekFSREbG-",
    "outputId": "4bb25e5f-4d92-4120-c20c-9f32e84aa792"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor.gender</th>\n",
       "      <th>gr.amount</th>\n",
       "      <th>movie.country</th>\n",
       "      <th>movie.directed_by</th>\n",
       "      <th>movie.estimated_budget</th>\n",
       "      <th>movie.genre</th>\n",
       "      <th>movie.gross_revenue</th>\n",
       "      <th>movie.initial_release_date</th>\n",
       "      <th>movie.language</th>\n",
       "      <th>movie.locations</th>\n",
       "      <th>movie.music</th>\n",
       "      <th>movie.produced_by</th>\n",
       "      <th>movie.production_companies</th>\n",
       "      <th>movie.rating</th>\n",
       "      <th>movie.starring.actor</th>\n",
       "      <th>movie.starring.character</th>\n",
       "      <th>movie.subjects</th>\n",
       "      <th>person.date_of_birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actor.gender  gr.amount  movie.country  movie.directed_by  \\\n",
       "0             0          0              0                  0   \n",
       "1             0          0              0                  0   \n",
       "2             0          0              0                  0   \n",
       "3             0          0              0                  0   \n",
       "4             1          0              0                  0   \n",
       "\n",
       "   movie.estimated_budget  movie.genre  movie.gross_revenue  \\\n",
       "0                       0            0                    0   \n",
       "1                       0            0                    0   \n",
       "2                       0            0                    0   \n",
       "3                       0            0                    0   \n",
       "4                       0            0                    0   \n",
       "\n",
       "   movie.initial_release_date  movie.language  movie.locations  movie.music  \\\n",
       "0                           0               0                0            0   \n",
       "1                           0               0                0            0   \n",
       "2                           0               0                0            0   \n",
       "3                           0               0                0            0   \n",
       "4                           0               0                0            0   \n",
       "\n",
       "   movie.produced_by  movie.production_companies  movie.rating  \\\n",
       "0                  0                           0             0   \n",
       "1                  0                           0             0   \n",
       "2                  0                           0             0   \n",
       "3                  0                           0             0   \n",
       "4                  0                           0             0   \n",
       "\n",
       "   movie.starring.actor  movie.starring.character  movie.subjects  \\\n",
       "0                     1                         1               0   \n",
       "1                     1                         0               0   \n",
       "2                     1                         0               0   \n",
       "3                     1                         1               0   \n",
       "4                     1                         0               0   \n",
       "\n",
       "   person.date_of_birth  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = one_hot_encoding(train_data)\n",
    "\n",
    "one_hot_encoded_df = pd.DataFrame(vectors)\n",
    "\n",
    "one_hot_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707955391905,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "ahnppttRGWDk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        # encodings should be a dictionary with keys like 'input_ids', 'attention_mask', etc.\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Since encodings is a dictionary, we correctly use .items() here\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1707955391905,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "vEXjk3CjHlX1"
   },
   "outputs": [],
   "source": [
    "# Preprocess the validation and test datasets\n",
    "train_texts = train_split['utterances'].tolist()\n",
    "validation_texts = validation_split['utterances'].tolist()\n",
    "# Replace with actual test data texts\n",
    "# test_texts = test_data['utterances'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1707955392286,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "PJkzxH7fHYJV"
   },
   "outputs": [],
   "source": [
    "# Tokenize all texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# You've tokenized train_texts here correctly\n",
    "# encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Assuming you've correctly prepared your labels as numpy arrays\n",
    "#train_labels = np.array(one_hot_encoding(train_split))\n",
    "#validation_labels = np.array(one_hot_encoding(validation_split))\n",
    "\n",
    "# Now, create the datasets with the correct encodings and labels\n",
    "#train_dataset = CustomDataset(encodings, train_labels)\n",
    "\n",
    "# For validation data, ensure you also tokenize it\n",
    "validation_encodings = tokenizer(validation_texts, truncation=True, padding=True, max_length=128)\n",
    "#validation_dataset = CustomDataset(validation_encodings, validation_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1707955392286,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "VtJAdvNvJnPu"
   },
   "outputs": [],
   "source": [
    "# Convert the list of dictionaries (one-hot encoded vectors) into a 2D list or numpy array\n",
    "def convert_to_matrix(vectors):\n",
    "    return np.array([list(vec.values()) for vec in vectors])\n",
    "\n",
    "# Convert your one-hot encoded labels into a format suitable for tensor conversion\n",
    "train_labels_matrix = convert_to_matrix(one_hot_encoding(train_split))\n",
    "validation_labels_matrix = convert_to_matrix(one_hot_encoding(validation_split))\n",
    "\n",
    "# Then, use these matrices when creating your datasets\n",
    "train_dataset = CustomDataset(train_encodings, train_labels_matrix)\n",
    "#validation_encodings = tokenizer(validation_texts, truncation=True, padding=True, max_length=128)\n",
    "validation_dataset = CustomDataset(validation_encodings, validation_labels_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707955392286,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "sO-0OJOKGYjE"
   },
   "outputs": [],
   "source": [
    "# train_labels = np.array(one_hot_encoding(train_split))\n",
    "# validation_labels = np.array(one_hot_encoding(validation_split))\n",
    "# # test_labels = np.array(one_hot_encoding(test_data))\n",
    "\n",
    "# train_dataset = CustomDataset(train_texts, train_labels)\n",
    "# validation_dataset = CustomDataset(validation_texts, validation_labels)\n",
    "# # test_dataset = CustomDataset(test_texts, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707955392286,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "rTrsDrh4GbjC"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    # Get the predictions and labels\n",
    "    logits = pred.predictions\n",
    "    true_labels = pred.label_ids\n",
    "\n",
    "    # Apply a sigmoid to the logits and round to get binary predictions\n",
    "    # This step converts logits to probabilities, then to binary values (0 or 1)\n",
    "    preds = np.where(torch.sigmoid(torch.tensor(logits)).numpy() > 0.5, 1, 0)\n",
    "\n",
    "    # Compute the F1 score, considering each label independently\n",
    "    f1 = f1_score(true_labels, preds, average='weighted')\n",
    "    accuracy = accuracy_score(true_labels, preds)\n",
    "\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'accuracy': accuracy,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707955392287,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "LqxV9JFwGeOL"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=1e-3,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 832,
     "status": "ok",
     "timestamp": 1707955393115,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "JH0xrJtEGiw2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "executionInfo": {
     "elapsed": 31479,
     "status": "ok",
     "timestamp": 1707955424591,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "9jPvD5oMGkjw",
    "outputId": "5ef8ddc3-d08d-4a48-c484-21ae01afde2f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='657' max='657' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [657/657 00:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.097668</td>\n",
       "      <td>0.653651</td>\n",
       "      <td>0.579487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.124866</td>\n",
       "      <td>0.663130</td>\n",
       "      <td>0.579487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.051832</td>\n",
       "      <td>0.869969</td>\n",
       "      <td>0.841026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "/home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=657, training_loss=0.10640439386600048, metrics={'train_runtime': 45.034, 'train_samples_per_second': 116.312, 'train_steps_per_second': 14.589, 'total_flos': 53471488573440.0, 'train_loss': 0.10640439386600048, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = '244-finetuned'\n",
    "trainer.save_model(finetuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (0.20.3)\n",
      "Requirement already satisfied: filelock in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from huggingface_hub) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from requests->huggingface_hub) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/detrived/miniconda3/envs/244_2/lib/python3.11/site-packages (from requests->huggingface_hub) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c6ee08f6a5485d80945a9fe66171a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "#KEY: 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829c847450f74f01a9a7b78dfbbb9c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be9f1bc8b164723a5e9c8e5c19067ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/devashat/244-finetuned/commit/46e8b86dc0526cc35abb3d76f63f031d782f3040', commit_message='Upload tokenizer', commit_description='', oid='46e8b86dc0526cc35abb3d76f63f031d782f3040', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(finetuned_model, use_temp_dir=False)\n",
    "tokenizer.push_to_hub(finetuned_model, use_temp_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "executionInfo": {
     "elapsed": 11973,
     "status": "ok",
     "timestamp": 1707955436560,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "LuvqCqqhT1vQ",
    "outputId": "5e37facf-1924-4fbd-8a58-d2484e474823"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "\n",
    "# Tokenize the test data\n",
    "test_texts = test_data['utterances'].tolist()\n",
    "#test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# Move to the same device as the model\n",
    "#test_encodings = {key: val.to(model.device) for key, val in test_encodings.items()}\n",
    "\n",
    "\n",
    "# Create a pipeline for multi-label classification\n",
    "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0, return_all_scores=True)\n",
    "\n",
    "# Predict\n",
    "predictions = classifier(test_texts)\n",
    "\n",
    "# Define a threshold for determining label presence\n",
    "threshold = 0.5\n",
    "\n",
    "predicted_labels = []\n",
    "for prediction in predictions:\n",
    "    # Convert LABEL_X to actual label using unique_core_relations\n",
    "    # Extract the label index from each prediction\n",
    "    labels = [unique_core_relations[int(pred['label'].split('_')[-1])] for pred in prediction if pred['score'] > threshold]\n",
    "    predicted_labels.append(labels)\n",
    "\n",
    "# Join multiple labels by a separator if there are multiple\n",
    "predicted_labels_joined = [\"; \".join(labels) for labels in predicted_labels]\n",
    "\n",
    "# Create a DataFrame to save to CSV\n",
    "predictions_df = pd.DataFrame({\n",
    "    \"utterances\": test_texts,\n",
    "    \"Core Relations\": predicted_labels_joined\n",
    "})\n",
    "\n",
    "# Define the path where you want to save the predictions CSV\n",
    "predictions_csv_path = 'predictions.csv'\n",
    "predictions_df.to_csv(predictions_csv_path, index=False)\n",
    "\n",
    "predictions_csv_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707955436560,
     "user": {
      "displayName": "Devasha Trivedi",
      "userId": "12588209179894471912"
     },
     "user_tz": 480
    },
    "id": "udib_q2cUjJx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNKYDIDd7BQ+BSV9Ad2hY0T",
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
